<!DOCTYPE html>
<html><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="your description">
    <meta name="Author" content="Trevor McKay">
    <meta name="keywords" content="hugo blog">
    <link rel="stylesheet" href=https://www.trmckay.com/css/syntax.css>
    <link rel="stylesheet" href=https://www.trmckay.com/css/style.css>
    <script src="https://kit.fontawesome.com/1b7478c139.js" crossorigin="anonymous"></script>
    <title>Trevor McKay</title>
  </head><body><aside id="sidenav">
    <header>
    

    <a id="branding" href=https://www.trmckay.com>
        
            Trevor McKay
        
    </a>
    </header>

    <nav>
        
            		
            <a href="/"
                
            >
                <i class="fas fa-home fa-sm"></i>
                <span>home</span>
            </a>
        
            		
            <a href="https://github.com/trmckay"
                
                    target="_blank"
                
            >
                <i class="fab fa-github fa-ms"></i>
                <span>github</span>
            </a>
        
            		
            <a href="/about"
                
            >
                <i class="far fa-envelope"></i>
                <span>about</span>
            </a>
        
    </nav>
</aside>
<main id="main">
            <div class="content">
    
    <h1 id="title">Automate backups with rsync</h1>
    
      
    <nav id="TableOfContents"></nav>
    <p>Everyone knows how devastating it can be to lose all your personal
and configuration files to hardware failure. As such, most users have some way to keep their files
safe. Many choose to use some sort of dotfile management system. This is is a great choice as it
allows for version control and branches for multiple machines. However, dotfiles are not the only
thing you want to preserve. Furthermore, when it comes to backups, more redundancy is never a bad
thing.</p>
<p>When I was looking for a way to keep my files safe, I had a few criteria to find my solution. I
wanted my backups to be:</p>
<ul>
<li><strong>Automatic</strong>: laziness or neglect should not stop my backups from occurring</li>
<li><strong>Frequent</strong>: I don&rsquo;t want to be screwed because my PC failed the day before a monthly backup</li>
<li><strong>Efficient</strong>: if backups are frequent, I don&rsquo;t want to frequently be dedicating my
resources to them</li>
<li><strong>Distributed</strong>: in other words, keep them in the cloud</li>
</ul>
<p>I am also the type of person who tends to ignore existing solutions, for worse or for better. Why
spend half an hour reading documentation when I could spend three hours writing a script while
generating content for a blog post at the same time?</p>
<h1 id="my-solution">My solution</h1>
<p>Anyway, I went through a few failed attempts and eventually settled on the following solution: <code>rsync</code> to do
the synchronization of the target file systems and their destinations, <code>cronie</code>/<code>anacron</code> to
schedule and automate, and Dropbox for cloud storage (this can still be done with <code>rclone</code> and
another cloud service, e.g. Google Drive or Onedrive). Of course, you will need these programs if
you do not have them already.</p>
<h1 id="getting-familiar-with-_rsync_">Getting familiar with <em>rsync</em></h1>
<p>Let&rsquo;s first create a script&ndash;well, for now it&rsquo;s basically just one command&ndash;that can simply
copy one folder to another. We could use <code>cp</code>, but lets use <code>rsync</code> for <em>speed</em> (among other things).
Here it is:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/bash
</span><span class="cp"></span>
<span class="nv">SOURCE</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span>
<span class="nv">DEST</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$2</span><span class="s2">&#34;</span>

<span class="nb">echo</span> <span class="s2">&#34;Synchronizing </span><span class="nv">$SOURCE</span><span class="s2"> to </span><span class="nv">$DEST</span><span class="s2">...&#34;</span>
rsync -a --delete <span class="nv">$SOURCE</span> <span class="nv">$DEST</span>
</code></pre></div><p>This is arguably the most important command of the backup script we are
working up to, so let&rsquo;s take a moment to digest it. The <code>-a</code> (<code>--archive</code>) flag is to preserve
pretty much everything. <code>--delete</code> is whats going
to keep your backup from infinitely inflating. I said we were &ldquo;copying&rdquo; files earlier, but what
we&rsquo;re really doing is &ldquo;synchronizing&rdquo; them. This will make sure if a file is deleted in the
original, it will be later deleted in the backup. Let&rsquo;s not forget the source and target
directories. One lesson I had to learn the hard way, is that <code>rsync</code> is very picky about these
arguments. For example <code>rsync documents backups</code> will put a copy of <code>documents</code> in <code>backups</code> so the
resulting directory structure is <code>backups/documents</code>. <code>rsync documents/ backups</code> does something
slightly different. It copies the <em>contents</em> of <code>documents</code> to <code>backups</code>. So, if <code>documents</code>
contains a folder <code>school</code>, the resulting directory structure would be <code>backups/school</code>. This is
something to be mindful of as we expand our script.</p>
<h1 id="backing-up-more-than-one-directory">Backing up more than one directory</h1>
<p>Wouldn&rsquo;t it be nice if we could back up a bunch of directories at once? I
agree. We can put our sources and destinations in an array like so:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># sources for backups</span>
<span class="nb">declare</span> -a SOURCES
SOURCES<span class="o">[</span>0<span class="o">]=</span><span class="s2">&#34;/home&#34;</span>
SOURCES<span class="o">[</span>1<span class="o">]=</span><span class="s2">&#34;/etc&#34;</span>
SOURCES<span class="o">[</span>2<span class="o">]=</span><span class="s2">&#34;/var/log&#34;</span>

<span class="c1"># destinations for backup</span>
<span class="nb">declare</span> -a DESTINATIONS
DESTINATIONS<span class="o">[</span>0<span class="o">]=</span><span class="s2">&#34;/mnt/hdd1/backups/daily&#34;</span>
DESTINATIONS<span class="o">[</span>1<span class="o">]=</span><span class="s2">&#34;/mnt/hdd0/backups/daily&#34;</span>

<span class="k">for</span> CURR_SOURCE in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">SOURCES</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
    <span class="k">for</span> CURR_DEST in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">DESTINATIONS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
        rsync -a --quiet --delete <span class="nv">$CURR_SOURCE</span> <span class="nv">$CURR_DEST</span>/<span class="k">$(</span>dirname <span class="nv">$CURR_SOURCE</span><span class="k">)</span>
    <span class="k">done</span>
<span class="k">done</span>
</code></pre></div><p>Now, we have a script that will take each source and back it up to each destination. Ideally, your
destinations are all on different drives. That&rsquo;s +1 point in the distributed criterion. Furthermore,
if your destinations are connected via SSH, you can use <code>rsync</code> like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">rsync -a --quiet --delete --rsh<span class="o">=</span>ssh <span class="nv">$CURR_SOURCE</span> <span class="nv">$CURR_DEST</span>
</code></pre></div><h1 id="adding-some-nice-features">Adding some nice features</h1>
<p>This is a good start, but we are still missing some QoL features. Some that came to mind when
writing this were notifications, backup rotation, and checking that destinations exist.</p>
<p>Beginning with device checking, I went for the &ldquo;low-tech but definitely works&rdquo; approach. You can
simply declare an array of all the mount locations the script will be writing to and check them:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># these disks will be checked on run</span>
<span class="nb">declare</span> -a DISKS
DISKS<span class="o">[</span>0<span class="o">]=</span><span class="s2">&#34;/mnt/hdd0&#34;</span>
DISKS<span class="o">[</span>1<span class="o">]=</span><span class="s2">&#34;/mnt/hdd1&#34;</span>

<span class="k">for</span> CURR_DISK in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">DISKS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
    <span class="k">if</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="k">$(</span>mount <span class="p">|</span> grep <span class="nv">$CURR_DISK</span><span class="k">)</span><span class="s2">&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
        <span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$CURR_DISK</span><span class="s2"> found&#34;</span>
    <span class="k">else</span>
        <span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$CURR_DISK</span><span class="s2"> not found, aborting&#34;</span>
        <span class="nb">exit</span>
    <span class="k">fi</span>
<span class="k">done</span>
</code></pre></div><p>As for notifications, <code>notify-send</code> will work just fine as long as you have a notification server
set up (if you don&rsquo;t know what that is, don&rsquo;t worry, you probably have one). I just have my script
issue a notification when it runs and when it finishes. It can be useful to keep track of that
especially when we start automating it. It is worth noting, however, that running <code>notify-send</code> as
root will have some unintended consequences. If you are backing up anything other than your own home
directory, this will certainly affect you. You can use this function to work around that issue
(credit goes to
<a href="https://stackoverflow.com/questions/28195805/running-notify-send-as-root">Fabio A. on StackOverflow</a>
for that):</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="k">function</span> notify-send<span class="o">()</span> <span class="o">{</span>
    <span class="nb">local</span> <span class="nv">display</span><span class="o">=</span><span class="s2">&#34;:</span><span class="k">$(</span>ls /tmp/.X11-unix/* <span class="p">|</span> sed <span class="s1">&#39;s#/tmp/.X11-unix/X##&#39;</span> <span class="p">|</span> head -n 1<span class="k">)</span><span class="s2">&#34;</span>
    <span class="nb">local</span> <span class="nv">user</span><span class="o">=</span><span class="k">$(</span>who <span class="p">|</span> grep <span class="s1">&#39;(&#39;</span><span class="nv">$display</span><span class="s1">&#39;)&#39;</span> <span class="p">|</span> awk <span class="s1">&#39;{print $1}&#39;</span> <span class="p">|</span> head -n 1<span class="k">)</span>
    <span class="nb">local</span> <span class="nv">uid</span><span class="o">=</span><span class="k">$(</span>id -u <span class="nv">$user</span><span class="k">)</span>
    sudo -u <span class="nv">$user</span> <span class="nv">DISPLAY</span><span class="o">=</span><span class="nv">$display</span> <span class="nv">DBUS_SESSION_BUS_ADDRESS</span><span class="o">=</span>unix:path<span class="o">=</span>/run/user/<span class="nv">$uid</span>/bus notify-send <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span>
<span class="o">}</span>
</code></pre></div><p>One last feature to add is backup rotation. Like I said earlier, redundancy is never bad. So it
can&rsquo;t hurt to keep more if you can spare the disk space. In my case, I opted for one level of
redundancy, but the logic is simple to adapt to more than one level. Essentially, before backing up
the source directory to the target, the target is copied to a <code>.old</code> directory.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="k">for</span> CURR_DEST in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">DESTINATIONS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
    rsync -a --quiet --delete <span class="nv">$CURR_DEST</span>/* <span class="nv">$CURR_DEST</span>.old
<span class="k">done</span>
</code></pre></div><h1 id="bringing-it-all-together">Bringing it all together</h1>
<p>Let&rsquo;s take these concepts and make them into a single useful script.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/bash
</span><span class="cp"></span>
<span class="k">function</span> notify-send<span class="o">()</span> <span class="o">{</span>
    <span class="nb">local</span> <span class="nv">display</span><span class="o">=</span><span class="s2">&#34;:</span><span class="k">$(</span>ls /tmp/.X11-unix/* <span class="p">|</span> sed <span class="s1">&#39;s#/tmp/.X11-unix/X##&#39;</span> <span class="p">|</span> head -n 1<span class="k">)</span><span class="s2">&#34;</span>
    <span class="nb">local</span> <span class="nv">user</span><span class="o">=</span><span class="k">$(</span>who <span class="p">|</span> grep <span class="s1">&#39;(&#39;</span><span class="nv">$display</span><span class="s1">&#39;)&#39;</span> <span class="p">|</span> awk <span class="s1">&#39;{print $1}&#39;</span> <span class="p">|</span> head -n 1<span class="k">)</span>
    <span class="nb">local</span> <span class="nv">uid</span><span class="o">=</span><span class="k">$(</span>id -u <span class="nv">$user</span><span class="k">)</span>
    sudo -u <span class="nv">$user</span> <span class="nv">DISPLAY</span><span class="o">=</span><span class="nv">$display</span> <span class="nv">DBUS_SESSION_BUS_ADDRESS</span><span class="o">=</span>unix:path<span class="o">=</span>/run/user/<span class="nv">$uid</span>/bus notify-send <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span>
<span class="o">}</span>

<span class="c1"># sources for backups</span>
<span class="nb">declare</span> -a TARGETS
TARGETS<span class="o">[</span>0<span class="o">]=</span><span class="s2">&#34;/home&#34;</span>
TARGETS<span class="o">[</span>1<span class="o">]=</span><span class="s2">&#34;/etc&#34;</span>
TARGETS<span class="o">[</span>2<span class="o">]=</span><span class="s2">&#34;/var/log&#34;</span>

<span class="c1"># destinations for backup</span>
<span class="c1"># folders will contain ALL targets after backup</span>
<span class="nb">declare</span> -a DESTINATIONS
DESTINATIONS<span class="o">[</span>0<span class="o">]=</span><span class="s2">&#34;/mnt/hdd1/backups/daily&#34;</span>
DESTINATIONS<span class="o">[</span>1<span class="o">]=</span><span class="s2">&#34;/mnt/hdd0/backups/daily&#34;</span>

<span class="c1"># these disks will be checked on run</span>
<span class="nb">declare</span> -a DISKS
DISKS<span class="o">[</span>0<span class="o">]=</span><span class="s2">&#34;/mnt/hdd0&#34;</span>
DISKS<span class="o">[</span>1<span class="o">]=</span><span class="s2">&#34;/mnt/hdd1&#34;</span>

<span class="nb">echo</span> <span class="s2">&#34;Time of backup: </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">&#34;</span>
notify-send --urgency<span class="o">=</span>critical <span class="s2">&#34;Starting backup&#34;</span>

<span class="nb">echo</span> <span class="s2">&#34;Checking disks...&#34;</span>
<span class="k">for</span> CURR_DISK in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">DISKS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
    <span class="k">if</span> <span class="o">[</span> -z <span class="s2">&#34;</span><span class="k">$(</span>mount <span class="p">|</span> grep <span class="nv">$CURR_DISK</span><span class="k">)</span><span class="s2">&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
        <span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$CURR_DISK</span><span class="s2"> is not mounted, aborting&#34;</span>
        <span class="nb">exit</span>
    <span class="k">fi</span>
<span class="k">done</span>

<span class="nb">echo</span> <span class="s2">&#34;Rotating backups...&#34;</span>
<span class="k">for</span> CURR_DEST in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">DESTINATIONS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
    <span class="k">if</span> <span class="o">[</span> -d <span class="nv">$CURR_DEST</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
        rsync -a --quiet --delete <span class="nv">$CURR_DEST</span>/* <span class="nv">$CURR_DEST</span>.old &gt; /dev/null <span class="p">&amp;</span>
    <span class="k">fi</span>
<span class="k">done</span>
<span class="nb">wait</span>

<span class="nb">echo</span> <span class="s2">&#34;Synchronizing sources to destinations...&#34;</span>
<span class="k">for</span> CURR_SOURCE in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">TARGETS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
    <span class="k">for</span> CURR_DEST in <span class="s2">&#34;</span><span class="si">${</span><span class="nv">DESTINATIONS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">do</span>
        mkdir -p <span class="nv">$CURR_DEST</span>/<span class="nv">$CURR_SOURCE</span>
        rsync -a --quiet --delete <span class="nv">$CURR_SOURCE</span> <span class="nv">$CURR_DEST</span>/<span class="k">$(</span>dirname <span class="nv">$CURR_SOURCE</span><span class="k">)</span> &gt; /dev/null <span class="p">&amp;</span>
    <span class="k">done</span>
<span class="k">done</span>
<span class="nb">wait</span>

<span class="nb">echo</span> <span class="s2">&#34;Backup complete!&#34;</span>
notify-send --urgency<span class="o">=</span>normal <span class="s2">&#34;Backup complete&#34;</span>
</code></pre></div><p>If you look closely, you&rsquo;ll see that the final script makes modifications to most the code we&rsquo;ve
written so far. Most of it is just small fixes to make everything work together and background processes to
speed things up. Still, the central idea remains the same: take an array of sources and copy them to
an array of destinations. Make sure to modify the sources and destinations to your liking before
running it. Also, <strong>do not use user specific environment variables</strong>! If you automate this later,
<code>anacron</code> will be running your script as root.</p>
<p>Run the script and with any luck you will see something like this:</p>
<pre><code>Time of backup: Fri Sep 18 07:12:22 PM PDT 2020
Checking disks...
Rotating backups...
Synchronizing sources to destinations...
Backup complete!
</code></pre><h1 id="i-am-lazy-sane-and-want-to-automate-this">I am lazy (sane) and want to automate this</h1>
<p>This is something, but it would be a lot more convenient if this happened automatically, say, once a
day. Thankfully, this can be done pretty simply with <code>cronie</code>/<code>anacron</code>. We want to set up a job
that runs this script once a day. We could use <code>cron</code> to do this every morning at 10:00 by adding
the following to our crontab:</p>
<pre><code class="language-cron" data-lang="cron">0 10 * * * /path/to/backup.sh
</code></pre><p>But, what if you wake up every day at 10:01 for a week, and the script never runs? Tough luck, I
guess&ndash;unless you use an asynchronous job. <code>cronie</code> comes with this capability built in. Simply
place a link to the script in <code>/etc/cron.daily</code> and it will run every day. However, make sure your
link doesn&rsquo;t end it <code>.sh</code>. For some reason, <code>run-parts</code> (the tool that <code>cronie</code> uses to run all the
executables in a directory) doesn&rsquo;t like that. You should also make sure that there is a cron job to
check for asynchronous jobs. You should see something like this in <code>/etc/crontab</code>. If not, add it.</p>
<pre><code>17 *    * * *   root    cd / &amp;&amp; run-parts --report /etc/cron.hourly
25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )
47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )
52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly )
</code></pre><p>And with that, we have fully automated local backups that will run daily, usually within half an hour
of logging in.</p>
<h1 id="backing-up-to-the-cloud">Backing up to the cloud</h1>
<p>Think to yourself: <em>if my computer were to spontaneously combust, would my backups be safe?</em> If the
answer is no, you should probably be backing up to the cloud.</p>
<p>I use Dropbox, and if you do too, doing this is actually pretty simple. Simply copy your backups to
your Dropbox folder every week or so. Of course, we are going to automate this. Thankfully, this is
much simpler than our other script. Here is the script I use to take my daily backup, compress it,
and copy it to my Dropbox.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/bash
</span><span class="cp"></span>
<span class="nv">WORKING_DIR</span><span class="o">=</span><span class="s2">&#34;/mnt/hdd0/&#34;</span>
<span class="nv">SOURCE_DIR</span><span class="o">=</span><span class="s2">&#34;backups/daily&#34;</span>
<span class="nv">DESTINATION_FILE</span><span class="o">=</span><span class="s2">&#34;/mnt/hdd0/Dropbox/backups/backup.tar.gz&#34;</span>

<span class="nb">cd</span> <span class="nv">$WORKING_DIR</span>
tar cf - <span class="nv">$SOURCE_DIR</span> <span class="p">|</span> pigz &gt; <span class="nv">$DESTINATION_FILE</span>
</code></pre></div><p>You can set this up as a asynchronous cron job, just like the local backup. Make a link to that
script in <code>/etc/cron.weekly</code> and you&rsquo;re good to go.</p>
<p>If you are not using Dropbox, this is a little trickier to do. However, it is possible. <code>rclone</code> is
a utility that supports Onedrive, Google Drive, and more. It&rsquo;s syntax is very similar to <code>rsync</code>'s.
I&rsquo;m sure the local backup script provides plenty of inspiration for creating your own script with
<code>rclone</code>. Good luck!</p>
<h1 id="conclusion">Conclusion</h1>
<p>So, looking back over the checklist we got: automatic ✓, frequent ✓, efficient ✓*, distributed ✓. Some
might argue that spending hours writing a script for a problem that has already been solved is not
efficient. Maybe they have a point. But, you wouldn&rsquo;t be reading random programming blogs if that
approach didn&rsquo;t appeal to you at least a little bit.</p>

    
    <div class="nav-next-prev">
        <div class="nav-prev">
            
                <a class="grayed-out" href="javascript:void()"><i class="fas fa-chevron-left"></i></a>
            
        </div>
        <a class="nav-top" href="#">top</i></a>
        <div class="nav-next">
            
                <a href="https://www.trmckay.com/posts/fib_asm/"><i class="fas fa-chevron-right"></i></a>
            
        </div>
    </div>
    

            </div><footer>
<div class="footer-content">

  <div class="contact-info">
      
          <div class="footer-mail">
          <i class="far fa-envelope"></i> <a href="mailto:tm@trmckay.com">tm@trmckay.com</a> </div>
      
      
  </div>


<p class="copyright meta">Copyright © 2021, Trevor McKay</p>

</div>
</footer></main>
    </body>
    <script src=https://www.trmckay.com/js/navbutton.js></script>
</html>
